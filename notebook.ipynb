{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 15:19:34.059 python[1962:18691] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743891575.427373   18691 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M3 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1743891575.437252   49122 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743891575.444915   49122 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743891575.447846   49118 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face mesh visualization: OFF\n",
      "Face mesh visualization: ON\n",
      "Face mesh visualization: OFF\n",
      "Face mesh visualization: ON\n",
      "Face mesh visualization: OFF\n",
      "Face mesh visualization: ON\n",
      "Face mesh visualization: OFF\n",
      "Face mesh visualization: ON\n",
      "Face mesh visualization: OFF\n",
      "Face mesh visualization: ON\n",
      "Face mesh visualization: OFF\n",
      "Face mesh visualization: ON\n",
      "Face mesh visualization: OFF\n",
      "Face mesh visualization: ON\n",
      "Face mesh visualization: OFF\n",
      "Face mesh visualization: ON\n",
      "Face mesh visualization: OFF\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize MediaPipe solutions\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "def get_avg_color(region):\n",
    "    avg_color_per_row = np.average(region, axis=0)\n",
    "    avg_color = np.average(avg_color_per_row, axis=0)\n",
    "    return avg_color\n",
    "\n",
    "def bgr_to_hex(bgr):\n",
    "    r, g, b = int(bgr[2]), int(bgr[1]), int(bgr[0])\n",
    "    return \"#{:02x}{:02x}{:02x}\".format(r, g, b).upper()\n",
    "\n",
    "def sample_feature_color(frame, landmarks, idx, region_size=6):\n",
    "    h, w, _ = frame.shape\n",
    "    x = int(landmarks.landmark[idx].x * w)\n",
    "    y = int(landmarks.landmark[idx].y * h)\n",
    "    patch = frame[y-region_size:y+region_size, x-region_size:x+region_size]\n",
    "    if patch.size == 0:\n",
    "        return None, (x, y)\n",
    "    avg_bgr = get_avg_color(patch)\n",
    "    return avg_bgr, (x, y)\n",
    "\n",
    "def initialize_csv(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerow(['Timestamp', 'Eye_R', 'Eye_G', 'Eye_B', 'Eye_Hex', \n",
    "                               'Lips_R', 'Lips_G', 'Lips_B', 'Lips_Hex',\n",
    "                               'Cheek_R', 'Cheek_G', 'Cheek_B', 'Cheek_Hex',\n",
    "                               'Hair_R', 'Hair_G', 'Hair_B', 'Hair_Hex'])\n",
    "    return filename\n",
    "\n",
    "def append_to_csv(filename, feature_colors):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    row_data = [timestamp]\n",
    "    \n",
    "    for feature in ['Eye', 'Lips', 'Cheek', 'Hair']:\n",
    "        if feature in feature_colors and feature_colors[feature] is not None:\n",
    "            color_bgr = feature_colors[feature]\n",
    "            r, g, b = int(color_bgr[2]), int(color_bgr[1]), int(color_bgr[0])\n",
    "            hex_color = bgr_to_hex(color_bgr)\n",
    "            row_data.extend([r, g, b, hex_color])\n",
    "        else:\n",
    "            row_data.extend([None, None, None, None])\n",
    "    \n",
    "    with open(filename, 'a', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(row_data)\n",
    "\n",
    "def start_color_analysis():\n",
    "    csv_filename = \"beyonce-features.csv\"\n",
    "    initialize_csv(csv_filename)\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Custom drawing specifications with blue color for mesh\n",
    "    blue_mesh_spec = mp_drawing.DrawingSpec(color=(255, 100, 200), thickness=1, circle_radius=1)\n",
    "    \n",
    "    # MediaPipe FaceMesh configuration\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    ) as face_mesh:\n",
    "        \n",
    "        recording = False\n",
    "        show_mesh = True  # Toggle for showing/hiding the facial mesh\n",
    "        feature_colors = {}\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            # Convert to RGB for MediaPipe\n",
    "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Process the image\n",
    "            results = face_mesh.process(image_rgb)\n",
    "            \n",
    "            # Make a copy of the frame for visualization\n",
    "            display_frame = frame.copy()\n",
    "            \n",
    "            if results.multi_face_landmarks:\n",
    "                face_landmarks = results.multi_face_landmarks[0]\n",
    "                \n",
    "                # Draw the facial mesh if enabled\n",
    "                if show_mesh:\n",
    "                    # Draw tessellation with custom blue color\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=display_frame,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                        landmark_drawing_spec=None,\n",
    "                        connection_drawing_spec=blue_mesh_spec\n",
    "                    )\n",
    "                \n",
    "                features = {\n",
    "                    'Eye': 468,   # Left iris center\n",
    "                    'Lips': 13,   # Lower lip center\n",
    "                    'Cheek': 205, # Left cheek\n",
    "                    'Hair': 295   # Eyebrow, in place for hair color\n",
    "                }\n",
    "                \n",
    "                # Reset feature_colors for this frame\n",
    "                feature_colors = {}\n",
    "                \n",
    "                y_offset = 20\n",
    "                for i, (feature, idx) in enumerate(features.items()):\n",
    "                    color_bgr, (x, y) = sample_feature_color(frame, face_landmarks, idx)\n",
    "                    if color_bgr is not None:\n",
    "                        feature_colors[feature] = color_bgr\n",
    "                        r, g, b = int(color_bgr[2]), int(color_bgr[1]), int(color_bgr[0])\n",
    "                        hex_color = bgr_to_hex(color_bgr)\n",
    "                        \n",
    "                        # Text display\n",
    "                        text = f\"{feature}: RGB({r},{g},{b}) | {hex_color}\"\n",
    "                        cv2.putText(display_frame, text, (10, 30 + y_offset * i), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                        \n",
    "                        # Color swatch next to face\n",
    "                        swatch_x = x + 10\n",
    "                        swatch_y = y - 10\n",
    "                        cv2.rectangle(display_frame, (swatch_x, swatch_y), (swatch_x + 40, swatch_y + 20), (b, g, r), -1)\n",
    "                        cv2.rectangle(display_frame, (swatch_x, swatch_y), (swatch_x + 40, swatch_y + 20), (0, 0, 0), 1)\n",
    "                        \n",
    "                        # Highlight feature point with bright red (to stand out against blue mesh)\n",
    "                        cv2.circle(display_frame, (x, y), 3, (255, 255, 255), -1)\n",
    "            \n",
    "            # Display recording status\n",
    "            if recording:\n",
    "                cv2.putText(display_frame, \"Recording: ON (Press 'r' to stop)\", (10, display_frame.shape[0] - 20), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "            else:\n",
    "                cv2.putText(display_frame, \"Recording: OFF (Press 'r' to start)\", (10, display_frame.shape[0] - 20), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                \n",
    "            # Display CSV status and controls\n",
    "            cv2.putText(display_frame, f\"CSV: {csv_filename}\", (10, display_frame.shape[0] - 50), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "            cv2.putText(display_frame, \"Press 'm' to toggle mesh\", (10, display_frame.shape[0] - 80), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "                       \n",
    "            # Show current frame    \n",
    "            cv2.imshow('KoreAI Analyzer – Feature Colors', display_frame)\n",
    "            \n",
    "            # Handle keyboard input\n",
    "            key = cv2.waitKey(5) & 0xFF\n",
    "            if key == 27:  # ESC key\n",
    "                break\n",
    "            elif key == ord('r'):  # Toggle recording\n",
    "                recording = not recording\n",
    "                if recording:\n",
    "                    print(f\"Recording started. Data will be saved to {csv_filename}\")\n",
    "                else:\n",
    "                    print(f\"Recording stopped. Data saved to {csv_filename}\")\n",
    "            elif key == ord('s') and len(feature_colors) > 0:  # Manual save current frame\n",
    "                append_to_csv(csv_filename, feature_colors)\n",
    "                print(f\"Snapshot saved to {csv_filename}\")\n",
    "            elif key == ord('m'):  # Toggle mesh visualization\n",
    "                show_mesh = not show_mesh\n",
    "                print(f\"Face mesh visualization: {'ON' if show_mesh else 'OFF'}\")\n",
    "            \n",
    "            # If recording and we have detected features, append to CSV\n",
    "            if recording and results.multi_face_landmarks and len(feature_colors) > 0:\n",
    "                append_to_csv(csv_filename, feature_colors)\n",
    "                \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Analysis complete. Data saved to {csv_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_color_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eye_R       34.209302\n",
       "Eye_G       32.511628\n",
       "Eye_B       36.825581\n",
       "Lips_R     110.872093\n",
       "Lips_G      57.104651\n",
       "Lips_B      58.406977\n",
       "Cheek_R    207.418605\n",
       "Cheek_G    143.069767\n",
       "Cheek_B    118.081395\n",
       "Hair_R      59.767442\n",
       "Hair_G      52.406977\n",
       "Hair_B      49.406977\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sp_df = pd.read_csv('sp-features.csv')[['Eye_R', 'Eye_G', 'Eye_B', \n",
    "                               'Lips_R', 'Lips_G', 'Lips_B',\n",
    "                               'Cheek_R', 'Cheek_G', 'Cheek_B',\n",
    "                               'Hair_R', 'Hair_G', 'Hair_B']]\n",
    "\n",
    "sp_avg = sp_df.mean(axis=0)\n",
    "\n",
    "sp_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
