{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 09:21:49.557 python[12387:228609] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743956510.860650  228609 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M3 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1743956510.871788  246181 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743956510.880907  246189 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743956510.901252  246181 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 181\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalysis complete. Data saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 181\u001b[0m     \u001b[43mstart_color_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 81\u001b[0m, in \u001b[0;36mstart_color_analysis\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m feature_colors \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m---> 81\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize MediaPipe solutions\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "def get_avg_color(region):\n",
    "    avg_color_per_row = np.average(region, axis=0)\n",
    "    avg_color = np.average(avg_color_per_row, axis=0)\n",
    "    return avg_color\n",
    "\n",
    "def bgr_to_hex(bgr):\n",
    "    r, g, b = int(bgr[2]), int(bgr[1]), int(bgr[0])\n",
    "    return \"#{:02x}{:02x}{:02x}\".format(r, g, b).upper()\n",
    "\n",
    "def sample_feature_color(frame, landmarks, idx, region_size=6):\n",
    "    h, w, _ = frame.shape\n",
    "    x = int(landmarks.landmark[idx].x * w)\n",
    "    y = int(landmarks.landmark[idx].y * h)\n",
    "    patch = frame[y-region_size:y+region_size, x-region_size:x+region_size]\n",
    "    if patch.size == 0:\n",
    "        return None, (x, y)\n",
    "    avg_bgr = get_avg_color(patch)\n",
    "    return avg_bgr, (x, y)\n",
    "\n",
    "def initialize_csv(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerow(['Timestamp', 'Eye_R', 'Eye_G', 'Eye_B', 'Eye_Hex', \n",
    "                               'Lips_R', 'Lips_G', 'Lips_B', 'Lips_Hex',\n",
    "                               'Cheek_R', 'Cheek_G', 'Cheek_B', 'Cheek_Hex',\n",
    "                               'Hair_R', 'Hair_G', 'Hair_B', 'Hair_Hex'])\n",
    "    return filename\n",
    "\n",
    "def append_to_csv(filename, feature_colors):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    row_data = [timestamp]\n",
    "    \n",
    "    for feature in ['Eye', 'Lips', 'Cheek', 'Hair']:\n",
    "        if feature in feature_colors and feature_colors[feature] is not None:\n",
    "            color_bgr = feature_colors[feature]\n",
    "            r, g, b = int(color_bgr[2]), int(color_bgr[1]), int(color_bgr[0])\n",
    "            hex_color = bgr_to_hex(color_bgr)\n",
    "            row_data.extend([r, g, b, hex_color])\n",
    "        else:\n",
    "            row_data.extend([None, None, None, None])\n",
    "    \n",
    "    with open(filename, 'a', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(row_data)\n",
    "\n",
    "def start_color_analysis():\n",
    "    csv_filename = \"av-features.csv\"\n",
    "    initialize_csv(csv_filename)\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Custom drawing specifications with blue color for mesh\n",
    "    blue_mesh_spec = mp_drawing.DrawingSpec(color=(250, 17, 219), thickness=1, circle_radius=1)\n",
    "    \n",
    "    # MediaPipe FaceMesh configuration\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    ) as face_mesh:\n",
    "        \n",
    "        recording = False\n",
    "        show_mesh = True  # Toggle for showing/hiding the facial mesh\n",
    "        feature_colors = {}\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            # Convert to RGB for MediaPipe\n",
    "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Process the image\n",
    "            results = face_mesh.process(image_rgb)\n",
    "            \n",
    "            # Make a copy of the frame for visualization\n",
    "            display_frame = frame.copy()\n",
    "            \n",
    "            if results.multi_face_landmarks:\n",
    "                face_landmarks = results.multi_face_landmarks[0]\n",
    "                \n",
    "                # Draw the facial mesh if enabled\n",
    "                if show_mesh:\n",
    "                    # Draw tessellation with custom blue color\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=display_frame,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                        landmark_drawing_spec=None,\n",
    "                        connection_drawing_spec=blue_mesh_spec\n",
    "                    )\n",
    "                \n",
    "                features = {\n",
    "                    'Eye': 468,   # Left iris center\n",
    "                    'Lips': 13,   # Lower lip center\n",
    "                    'Cheek': 205, # Left cheek\n",
    "                    'Hair': 295   # Eyebrow, in place for hair color\n",
    "                }\n",
    "                \n",
    "                # Reset feature_colors for this frame\n",
    "                feature_colors = {}\n",
    "                \n",
    "                y_offset = 20\n",
    "                for i, (feature, idx) in enumerate(features.items()):\n",
    "                    color_bgr, (x, y) = sample_feature_color(frame, face_landmarks, idx)\n",
    "                    if color_bgr is not None:\n",
    "                        feature_colors[feature] = color_bgr\n",
    "                        r, g, b = int(color_bgr[2]), int(color_bgr[1]), int(color_bgr[0])\n",
    "                        hex_color = bgr_to_hex(color_bgr)\n",
    "                        \n",
    "                        # Text display\n",
    "                        text = f\"{feature}: RGB({r},{g},{b}) | {hex_color}\"\n",
    "                        cv2.putText(display_frame, text, (10, 30 + y_offset * i), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                        \n",
    "                        # Color swatch next to face\n",
    "                        swatch_x = x + 10\n",
    "                        swatch_y = y - 10\n",
    "                        cv2.rectangle(display_frame, (swatch_x, swatch_y), (swatch_x + 40, swatch_y + 20), (b, g, r), -1)\n",
    "                        cv2.rectangle(display_frame, (swatch_x, swatch_y), (swatch_x + 40, swatch_y + 20), (0, 0, 0), 1)\n",
    "                        \n",
    "                        # Highlight feature point with bright red (to stand out against blue mesh)\n",
    "                        cv2.circle(display_frame, (x, y), 3, (255, 255, 255), -1)\n",
    "            \n",
    "            # Display recording status\n",
    "            if recording:\n",
    "                cv2.putText(display_frame, \"Recording: ON (Press 'r' to stop)\", (10, display_frame.shape[0] - 20), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "            else:\n",
    "                cv2.putText(display_frame, \"Recording: OFF (Press 'r' to start)\", (10, display_frame.shape[0] - 20), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                \n",
    "            # Display CSV status and controls\n",
    "            cv2.putText(display_frame, f\"CSV: {csv_filename}\", (10, display_frame.shape[0] - 50), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "            cv2.putText(display_frame, \"Press 'm' to toggle mesh\", (10, display_frame.shape[0] - 80), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "                       \n",
    "            # Show current frame    \n",
    "            cv2.imshow('KoreAI Analyzer â€“ Feature Colors', display_frame)\n",
    "            \n",
    "            # Handle keyboard input\n",
    "            key = cv2.waitKey(5) & 0xFF\n",
    "            if key == 27:  # ESC key\n",
    "                break\n",
    "            elif key == ord('r'):  # Toggle recording\n",
    "                recording = not recording\n",
    "                if recording:\n",
    "                    print(f\"Recording started. Data will be saved to {csv_filename}\")\n",
    "                else:\n",
    "                    print(f\"Recording stopped. Data saved to {csv_filename}\")\n",
    "            elif key == ord('s') and len(feature_colors) > 0:  # Manual save current frame\n",
    "                append_to_csv(csv_filename, feature_colors)\n",
    "                print(f\"Snapshot saved to {csv_filename}\")\n",
    "            elif key == ord('m'):  # Toggle mesh visualization\n",
    "                show_mesh = not show_mesh\n",
    "                print(f\"Face mesh visualization: {'ON' if show_mesh else 'OFF'}\")\n",
    "            \n",
    "            # If recording and we have detected features, append to CSV\n",
    "            if recording and results.multi_face_landmarks and len(feature_colors) > 0:\n",
    "                append_to_csv(csv_filename, feature_colors)\n",
    "                \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Analysis complete. Data saved to {csv_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_color_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'vk-features.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     transpose \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(avg)\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transpose\n\u001b[0;32m---> 12\u001b[0m vk \u001b[38;5;241m=\u001b[39m \u001b[43mcsv_to_df\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvk-features.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m dd \u001b[38;5;241m=\u001b[39m csv_to_df(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd-features.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m sp \u001b[38;5;241m=\u001b[39m csv_to_df(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msp-features.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m, in \u001b[0;36mcsv_to_df\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcsv_to_df\u001b[39m(file_name):\n\u001b[0;32m----> 4\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEye_R\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEye_G\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEye_B\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      5\u001b[0m                                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLips_R\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLips_G\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLips_B\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCheek_R\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCheek_G\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCheek_B\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHair_R\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHair_G\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHair_B\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      8\u001b[0m     avg \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      9\u001b[0m     transpose \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(avg)\u001b[38;5;241m.\u001b[39mtranspose()\n",
      "File \u001b[0;32m~/miniforge3/envs/dsc80/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/dsc80/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniforge3/envs/dsc80/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/dsc80/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniforge3/envs/dsc80/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'vk-features.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def csv_to_df(file_name):\n",
    "    df = pd.read_csv(file_name)[['Eye_R', 'Eye_G', 'Eye_B', \n",
    "                                'Lips_R', 'Lips_G', 'Lips_B',\n",
    "                                'Cheek_R', 'Cheek_G', 'Cheek_B',\n",
    "                                'Hair_R', 'Hair_G', 'Hair_B']]\n",
    "    avg = df.mean(axis=0)\n",
    "    transpose = pd.DataFrame(avg).transpose()\n",
    "    return transpose\n",
    "\n",
    "vk = csv_to_df('vk-features.csv')\n",
    "dd = csv_to_df('dd-features.csv')\n",
    "sp = csv_to_df('sp-features.csv')\n",
    "av = csv_to_df('av-features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/snigdhapodugu/miniforge3/envs/dsc80/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Undertone\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the data\n",
    "training = pd.read_csv('../csv/training_celebs.csv')[['undertone', 'Eye_R', 'Eye_G', 'Eye_B', \n",
    "                                           'Lips_R', 'Lips_G', 'Lips_B', 'Cheek_R', 'Cheek_G', \n",
    "                                           'Cheek_B', 'Hair_R', 'Hair_G', 'Hair_B']]\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X = training.drop(columns=['undertone'])\n",
    "y = training['undertone']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# List of numerical columns (features that are already numeric)\n",
    "num_columns = ['Eye_R', 'Eye_G', 'Eye_B', 'Lips_R', 'Lips_G', 'Lips_B', \n",
    "               'Cheek_R', 'Cheek_G', 'Cheek_B', 'Hair_R', 'Hair_G', 'Hair_B']\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "def predict_undertone(features):\n",
    "    pred = pipeline.predict(features)\n",
    "    return pred\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save the pipeline to a file\n",
    "joblib.dump(pipeline, '../models/undertone_classifier3.pkl')\n",
    "\n",
    "# predict_undertone(av)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/snigdhapodugu/miniforge3/envs/dsc80/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Season\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the data\n",
    "training = pd.read_csv('../csv/training_celebs.csv')[['season', 'Eye_R', 'Eye_G', 'Eye_B', \n",
    "                                           'Lips_R', 'Lips_G', 'Lips_B', 'Cheek_R', 'Cheek_G', \n",
    "                                           'Cheek_B', 'Hair_R', 'Hair_G', 'Hair_B']]\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X = training.drop(columns=['season'])\n",
    "y = training['season']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# List of numerical columns (features that are already numeric)\n",
    "num_columns = ['Eye_R', 'Eye_G', 'Eye_B', 'Lips_R', 'Lips_G', 'Lips_B', \n",
    "               'Cheek_R', 'Cheek_G', 'Cheek_B', 'Hair_R', 'Hair_G', 'Hair_B']\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "def predict_season(features):\n",
    "    pred = pipeline.predict(features)\n",
    "    return pred\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save the pipeline to a file\n",
    "joblib.dump(pipeline, '../models/season_classifier3.pkl')\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import colorsys\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "class ClothingColorGenerator:\n",
    "    def __init__(self):\n",
    "        # Initialize models for hue, saturation, and lightness predictions\n",
    "        self.hue_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        self.sat_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        self.light_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        \n",
    "        # Initialize scaler for input features\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # Train the models with synthetic data if no pre-trained models exist\n",
    "        self._train_with_synthetic_data()\n",
    "        \n",
    "    def _train_with_synthetic_data(self):\n",
    "        \"\"\"Train models with synthetic data representing color harmony principles\"\"\"\n",
    "        # Generate synthetic data based on color theory and seasonal preferences\n",
    "        # For real applications, this would be replaced with a dataset of expert-curated colors\n",
    "        \n",
    "        # Generate samples: skin colors (RGB) x seasons\n",
    "        np.random.seed(42)\n",
    "        n_samples = 5000\n",
    "        \n",
    "        # Random skin tones across a spectrum\n",
    "        skin_r = np.random.uniform(0.2, 0.9, n_samples)\n",
    "        skin_g = np.random.uniform(0.2, 0.8, n_samples)\n",
    "        skin_b = np.random.uniform(0.1, 0.7, n_samples)\n",
    "        \n",
    "        # Convert to HSL for feature engineering\n",
    "        skin_hsl = np.array([colorsys.rgb_to_hls(r, g, b) for r, g, b in zip(skin_r, skin_g, skin_b)])\n",
    "        skin_h, skin_l, skin_s = skin_hsl[:, 0], skin_hsl[:, 1], skin_hsl[:, 2]\n",
    "        \n",
    "        # Season encoding (one-hot)\n",
    "        seasons = np.random.choice(['summer', 'autumn', 'winter', 'spring'], n_samples)\n",
    "        season_summer = (seasons == 'summer').astype(int)\n",
    "        season_autumn = (seasons == 'autumn').astype(int)\n",
    "        season_winter = (seasons == 'winter').astype(int)\n",
    "        season_spring = (seasons == 'spring').astype(int)\n",
    "        \n",
    "        # Feature matrix\n",
    "        X = np.column_stack([\n",
    "            skin_r, skin_g, skin_b, \n",
    "            skin_h, skin_l, skin_s,\n",
    "            season_summer, season_autumn, season_winter, season_spring\n",
    "        ])\n",
    "        \n",
    "        # Scale features\n",
    "        self.scaler.fit(X)\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        # Generate target colors based on color theory\n",
    "        # For each skin tone and season, create multiple harmonious colors\n",
    "        \n",
    "        # Helper functions to generate color harmonies with seasonal adjustments\n",
    "        def generate_hue_targets(h, season):\n",
    "            \"\"\"Generate harmonious hues with seasonal bias\"\"\"\n",
    "            h_deg = h * 360\n",
    "            \n",
    "            # Base harmonies (analogous, complementary, triadic)\n",
    "            harmonies = [\n",
    "                (h_deg + 30) % 360,  # analogous +30\n",
    "                (h_deg - 30) % 360,  # analogous -30\n",
    "                (h_deg + 180) % 360,  # complementary\n",
    "                (h_deg + 120) % 360,  # triadic +120\n",
    "                (h_deg - 120) % 360,  # triadic -120\n",
    "            ]\n",
    "            \n",
    "            # Season-specific hue shifts\n",
    "            season_shifts = {\n",
    "                'summer': [-10, 0, 10, 20, 30],  # cooler colors\n",
    "                'autumn': [-30, -20, -10, 0, 10],  # warmer, earthier tones\n",
    "                'winter': [0, 10, 20, 30, 40],  # high contrast\n",
    "                'spring': [-20, -10, 0, 10, 20]   # bright, clear colors\n",
    "            }\n",
    "            \n",
    "            # Apply seasonal shifts to each harmony\n",
    "            results = []\n",
    "            for harmony in harmonies:\n",
    "                for shift in season_shifts[season]:\n",
    "                    results.append((harmony + shift) % 360)\n",
    "            \n",
    "            return np.array(results) / 360  # Normalize back to [0, 1]\n",
    "        \n",
    "        def generate_saturation_targets(s, season):\n",
    "            \"\"\"Generate saturation values with seasonal adjustments\"\"\"\n",
    "            base = s * 0.8  # Start with a relation to skin saturation\n",
    "            \n",
    "            # Season-specific saturation adjustments\n",
    "            modifiers = {\n",
    "                'summer': np.linspace(0.6, 0.8, 25),  # softer, muted\n",
    "                'autumn': np.linspace(0.7, 0.9, 25),  # rich, warm\n",
    "                'winter': np.linspace(0.8, 1.0, 25),  # clear, bright\n",
    "                'spring': np.linspace(0.7, 0.95, 25)  # clear, bright\n",
    "            }\n",
    "            \n",
    "            return np.clip(base + modifiers[season], 0.1, 1.0)\n",
    "        \n",
    "        def generate_lightness_targets(l, season):\n",
    "            \"\"\"Generate lightness values with seasonal adjustments\"\"\"\n",
    "            base = max(0.3, min(0.7, l))  # Keep within reasonable bounds\n",
    "            \n",
    "            # Season-specific lightness adjustments\n",
    "            modifiers = {\n",
    "                'summer': np.linspace(0.5, 0.8, 25),  # light to medium\n",
    "                'autumn': np.linspace(0.4, 0.7, 25),  # medium\n",
    "                'winter': np.linspace(0.3, 0.9, 25),  # high contrast\n",
    "                'spring': np.linspace(0.6, 0.9, 25)   # light to medium-light\n",
    "            }\n",
    "            \n",
    "            return np.clip(base + modifiers[season] - 0.5, 0.1, 0.9)\n",
    "        \n",
    "        # Generate target values for each sample\n",
    "        y_hue = []\n",
    "        y_sat = []\n",
    "        y_light = []\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            h_targets = generate_hue_targets(skin_h[i], seasons[i])\n",
    "            s_targets = generate_saturation_targets(skin_s[i], seasons[i])\n",
    "            l_targets = generate_lightness_targets(skin_l[i], seasons[i])\n",
    "            \n",
    "            # Expand X by repeating each row for each target color\n",
    "            if i == 0:\n",
    "                X_expanded = np.repeat([X_scaled[i]], len(h_targets), axis=0)\n",
    "            else:\n",
    "                X_expanded = np.vstack((X_expanded, np.repeat([X_scaled[i]], len(h_targets), axis=0)))\n",
    "            \n",
    "            y_hue.extend(h_targets)\n",
    "            y_sat.extend(s_targets)\n",
    "            y_light.extend(l_targets)\n",
    "        \n",
    "        # Train models\n",
    "        self.hue_model.fit(X_expanded, y_hue)\n",
    "        self.sat_model.fit(X_expanded, y_sat)\n",
    "        self.light_model.fit(X_expanded, y_light)\n",
    "    \n",
    "    def generate_clothing_colors(self, skin_rgb, season, num_colors=8):\n",
    "        \"\"\"\n",
    "        Generate clothing color recommendations based on skin RGB and season\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        skin_rgb : tuple or list\n",
    "            RGB values of the skin tone (0-255)\n",
    "        season : str\n",
    "            One of 'summer', 'autumn', 'winter', 'spring'\n",
    "        num_colors : int\n",
    "            Number of color recommendations to generate\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        numpy.ndarray\n",
    "            Array of recommended colors in RGB (0-255)\n",
    "        \"\"\"\n",
    "        # Normalize RGB values\n",
    "        r, g, b = [x / 255.0 for x in skin_rgb]\n",
    "        \n",
    "        # Convert to HSL for feature extraction\n",
    "        h, l, s = colorsys.rgb_to_hls(r, g, b)\n",
    "        \n",
    "        # Create season one-hot encoding\n",
    "        season_summer = 1 if season == 'summer' else 0\n",
    "        season_autumn = 1 if season == 'autumn' else 0\n",
    "        season_winter = 1 if season == 'winter' else 0\n",
    "        season_spring = 1 if season == 'spring' else 0\n",
    "        \n",
    "        # Create feature vector\n",
    "        X = np.array([[\n",
    "            r, g, b, h, l, s,\n",
    "            season_summer, season_autumn, season_winter, season_spring\n",
    "        ]])\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        # Make predictions for multiple colors by adding random noise to the input\n",
    "        X_variations = np.vstack([\n",
    "            X_scaled + np.random.normal(0, 0.1, X_scaled.shape) for _ in range(num_colors * 3)\n",
    "        ])\n",
    "        \n",
    "        # Predict HSL values\n",
    "        hue_preds = self.hue_model.predict(X_variations)\n",
    "        sat_preds = self.sat_model.predict(X_variations)\n",
    "        light_preds = self.light_model.predict(X_variations)\n",
    "        \n",
    "        # Convert predictions to valid HSL\n",
    "        hue_preds = np.clip(hue_preds, 0, 1)\n",
    "        sat_preds = np.clip(sat_preds, 0.1, 1)\n",
    "        light_preds = np.clip(light_preds, 0.1, 0.9)\n",
    "        \n",
    "        # Convert back to RGB\n",
    "        rgb_colors = []\n",
    "        for h_pred, l_pred, s_pred in zip(hue_preds, light_preds, sat_preds):\n",
    "            rgb = colorsys.hls_to_rgb(h_pred, l_pred, s_pred)\n",
    "            rgb_colors.append([c * 255 for c in rgb])\n",
    "        \n",
    "        # Select the most diverse set of colors by clustering\n",
    "        from sklearn.cluster import KMeans\n",
    "        kmeans = KMeans(n_clusters=num_colors, random_state=42)\n",
    "        kmeans.fit(rgb_colors)\n",
    "        \n",
    "        centers = kmeans.cluster_centers_\n",
    "        \n",
    "        # Return as numpy array\n",
    "        return np.array(centers)\n",
    "    \n",
    "    def save_model(self, filename=\"color_model.joblib\"):\n",
    "        \"\"\"Save the trained model to a file\"\"\"\n",
    "        model_data = {\n",
    "            'hue_model': self.hue_model,\n",
    "            'sat_model': self.sat_model,\n",
    "            'light_model': self.light_model,\n",
    "            'scaler': self.scaler\n",
    "        }\n",
    "        joblib.dump(model_data, filename)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(cls, filename=\"color_model.joblib\"):\n",
    "        \"\"\"Load a trained model from a file\"\"\"\n",
    "        generator = cls()\n",
    "        model_data = joblib.load(filename)\n",
    "        generator.hue_model = model_data['hue_model']\n",
    "        generator.sat_model = model_data['sat_model']\n",
    "        generator.light_model = model_data['light_model']\n",
    "        generator.scaler = model_data['scaler']\n",
    "        return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clothing_colors(skin_rgb, season, num_colors=8):\n",
    "    \"\"\"\n",
    "    Generate clothing color recommendations based on skin RGB and season\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    skin_rgb : tuple or list\n",
    "        RGB values of the skin tone (0-255)\n",
    "    season : str\n",
    "        One of 'summer', 'autumn', 'winter', 'spring'\n",
    "    num_colors : int\n",
    "        Number of color recommendations to generate\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Array of recommended colors in RGB (0-255)\n",
    "    \"\"\"\n",
    "    generator = ClothingColorGenerator()\n",
    "    return generator.generate_clothing_colors(skin_rgb, season, num_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>season</th>\n",
       "      <th>undertone</th>\n",
       "      <th>Eye_R</th>\n",
       "      <th>Eye_G</th>\n",
       "      <th>Eye_B</th>\n",
       "      <th>Eye_Hex</th>\n",
       "      <th>Lips_R</th>\n",
       "      <th>Lips_G</th>\n",
       "      <th>Lips_B</th>\n",
       "      <th>Lips_Hex</th>\n",
       "      <th>Cheek_R</th>\n",
       "      <th>Cheek_G</th>\n",
       "      <th>Cheek_B</th>\n",
       "      <th>Cheek_Hex</th>\n",
       "      <th>Hair_R</th>\n",
       "      <th>Hair_G</th>\n",
       "      <th>Hair_B</th>\n",
       "      <th>Hair_Hex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyonce</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Warm</td>\n",
       "      <td>93</td>\n",
       "      <td>101</td>\n",
       "      <td>108</td>\n",
       "      <td>#5D656C</td>\n",
       "      <td>127</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>#7F3C37</td>\n",
       "      <td>138</td>\n",
       "      <td>78</td>\n",
       "      <td>60</td>\n",
       "      <td>#8A4E3C</td>\n",
       "      <td>77</td>\n",
       "      <td>50</td>\n",
       "      <td>41</td>\n",
       "      <td>#4D3229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Warm</td>\n",
       "      <td>109</td>\n",
       "      <td>118</td>\n",
       "      <td>125</td>\n",
       "      <td>#6D767D</td>\n",
       "      <td>122</td>\n",
       "      <td>56</td>\n",
       "      <td>52</td>\n",
       "      <td>#7A3834</td>\n",
       "      <td>138</td>\n",
       "      <td>78</td>\n",
       "      <td>60</td>\n",
       "      <td>#8A4E3C</td>\n",
       "      <td>89</td>\n",
       "      <td>60</td>\n",
       "      <td>51</td>\n",
       "      <td>#593C33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Selena Gomez</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>114</td>\n",
       "      <td>124</td>\n",
       "      <td>130</td>\n",
       "      <td>#727C82</td>\n",
       "      <td>84</td>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "      <td>#541F1A</td>\n",
       "      <td>140</td>\n",
       "      <td>80</td>\n",
       "      <td>61</td>\n",
       "      <td>#8C503D</td>\n",
       "      <td>85</td>\n",
       "      <td>56</td>\n",
       "      <td>46</td>\n",
       "      <td>#55382E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hrithik Roshan</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Warm</td>\n",
       "      <td>112</td>\n",
       "      <td>120</td>\n",
       "      <td>126</td>\n",
       "      <td>#70787E</td>\n",
       "      <td>99</td>\n",
       "      <td>41</td>\n",
       "      <td>36</td>\n",
       "      <td>#632924</td>\n",
       "      <td>139</td>\n",
       "      <td>78</td>\n",
       "      <td>60</td>\n",
       "      <td>#8B4E3C</td>\n",
       "      <td>80</td>\n",
       "      <td>52</td>\n",
       "      <td>42</td>\n",
       "      <td>#50342A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sarah Rafferty</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>110</td>\n",
       "      <td>119</td>\n",
       "      <td>125</td>\n",
       "      <td>#6E777D</td>\n",
       "      <td>118</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>#763631</td>\n",
       "      <td>140</td>\n",
       "      <td>80</td>\n",
       "      <td>62</td>\n",
       "      <td>#8C503E</td>\n",
       "      <td>83</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>#53372D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Prince Harry</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Warm</td>\n",
       "      <td>112</td>\n",
       "      <td>120</td>\n",
       "      <td>126</td>\n",
       "      <td>#70787E</td>\n",
       "      <td>87</td>\n",
       "      <td>33</td>\n",
       "      <td>28</td>\n",
       "      <td>#57211C</td>\n",
       "      <td>140</td>\n",
       "      <td>80</td>\n",
       "      <td>61</td>\n",
       "      <td>#8C503D</td>\n",
       "      <td>83</td>\n",
       "      <td>55</td>\n",
       "      <td>43</td>\n",
       "      <td>#53372B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Michael PeÃ±a</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Warm</td>\n",
       "      <td>97</td>\n",
       "      <td>104</td>\n",
       "      <td>111</td>\n",
       "      <td>#61686F</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>#4B1915</td>\n",
       "      <td>139</td>\n",
       "      <td>78</td>\n",
       "      <td>60</td>\n",
       "      <td>#8B4E3C</td>\n",
       "      <td>80</td>\n",
       "      <td>53</td>\n",
       "      <td>42</td>\n",
       "      <td>#50352A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Taylor Zakhar Perez</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Cool</td>\n",
       "      <td>100</td>\n",
       "      <td>107</td>\n",
       "      <td>113</td>\n",
       "      <td>#646B71</td>\n",
       "      <td>114</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>#723330</td>\n",
       "      <td>140</td>\n",
       "      <td>80</td>\n",
       "      <td>61</td>\n",
       "      <td>#8C503D</td>\n",
       "      <td>83</td>\n",
       "      <td>55</td>\n",
       "      <td>46</td>\n",
       "      <td>#53372E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Maisie Richardson-Sellers</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Cool</td>\n",
       "      <td>108</td>\n",
       "      <td>117</td>\n",
       "      <td>124</td>\n",
       "      <td>#6C757C</td>\n",
       "      <td>102</td>\n",
       "      <td>42</td>\n",
       "      <td>38</td>\n",
       "      <td>#662A26</td>\n",
       "      <td>139</td>\n",
       "      <td>79</td>\n",
       "      <td>60</td>\n",
       "      <td>#8B4F3C</td>\n",
       "      <td>77</td>\n",
       "      <td>50</td>\n",
       "      <td>41</td>\n",
       "      <td>#4D3229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Alia Bhatt</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Warm</td>\n",
       "      <td>109</td>\n",
       "      <td>118</td>\n",
       "      <td>125</td>\n",
       "      <td>#6D767D</td>\n",
       "      <td>89</td>\n",
       "      <td>34</td>\n",
       "      <td>29</td>\n",
       "      <td>#59221D</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>61</td>\n",
       "      <td>#8B503D</td>\n",
       "      <td>79</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>#4F342B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name  season undertone  Eye_R  Eye_G  Eye_B  Eye_Hex  \\\n",
       "0                     Beyonce  Autumn      Warm     93    101    108  #5D656C   \n",
       "1                   Lady Gaga  Autumn      Warm    109    118    125  #6D767D   \n",
       "2                Selena Gomez  Winter   Neutral    114    124    130  #727C82   \n",
       "3              Hrithik Roshan  Autumn      Warm    112    120    126  #70787E   \n",
       "4              Sarah Rafferty  Autumn   Neutral    110    119    125  #6E777D   \n",
       "..                        ...     ...       ...    ...    ...    ...      ...   \n",
       "95               Prince Harry  Spring      Warm    112    120    126  #70787E   \n",
       "96               Michael PeÃ±a  Autumn      Warm     97    104    111  #61686F   \n",
       "97        Taylor Zakhar Perez  Winter      Cool    100    107    113  #646B71   \n",
       "98  Maisie Richardson-Sellers  Winter      Cool    108    117    124  #6C757C   \n",
       "99                 Alia Bhatt  Summer      Warm    109    118    125  #6D767D   \n",
       "\n",
       "    Lips_R  Lips_G  Lips_B Lips_Hex  Cheek_R  Cheek_G  Cheek_B Cheek_Hex  \\\n",
       "0      127      60      55  #7F3C37      138       78       60   #8A4E3C   \n",
       "1      122      56      52  #7A3834      138       78       60   #8A4E3C   \n",
       "2       84      31      26  #541F1A      140       80       61   #8C503D   \n",
       "3       99      41      36  #632924      139       78       60   #8B4E3C   \n",
       "4      118      54      49  #763631      140       80       62   #8C503E   \n",
       "..     ...     ...     ...      ...      ...      ...      ...       ...   \n",
       "95      87      33      28  #57211C      140       80       61   #8C503D   \n",
       "96      75      25      21  #4B1915      139       78       60   #8B4E3C   \n",
       "97     114      51      48  #723330      140       80       61   #8C503D   \n",
       "98     102      42      38  #662A26      139       79       60   #8B4F3C   \n",
       "99      89      34      29  #59221D      139       80       61   #8B503D   \n",
       "\n",
       "    Hair_R  Hair_G  Hair_B Hair_Hex  \n",
       "0       77      50      41  #4D3229  \n",
       "1       89      60      51  #593C33  \n",
       "2       85      56      46  #55382E  \n",
       "3       80      52      42  #50342A  \n",
       "4       83      55      45  #53372D  \n",
       "..     ...     ...     ...      ...  \n",
       "95      83      55      43  #53372B  \n",
       "96      80      53      42  #50352A  \n",
       "97      83      55      46  #53372E  \n",
       "98      77      50      41  #4D3229  \n",
       "99      79      52      43  #4F342B  \n",
       "\n",
       "[100 rows x 19 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('../csv/training_celebs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
